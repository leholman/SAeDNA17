seqtab <- makeSequenceTable(mergers)
View(seqtab)
table(nchar(getSequences(seqtab)))
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
system2("ls",args="-lh")
system2("usearch",)
system2("usearch",env = "PATH=PATH")
install_github("VascoElbrecht/JAMP", subdir="JAMP")
library("devtools")
install_github("VascoElbrecht/PrimerMiner", subdir="PrimerMiner")
install_github("VascoElbrecht/JAMP", subdir="JAMP")
library(JAMP)
U_truncate()
?U_truncate()
U_max_ee()
install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
?create
collapseNoMismatch <- function(seqtab, minOverlap=20, orderBy="abundance", identicalOnly=FALSE, vec=TRUE, verbose=FALSE) {
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
for(query in seqs) {
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
}
#libraries
library(dada2)
?fread
??fread
library(data.table)
rawdata <- fread("~/Desktop/finalDADA.out.csv",sep=",")
str(rawdata)
data <- as.matrix(rawdata)
datat[1,]
data[1,]
data[,1]
rownames(data)
rownames(data) <- data[,1]
rownames(data)
data2 <- data[,-1]
mode(data2)
data3 <- data2
mode(data3) <- "integer"
rowSums(data3)
rowSums(data3)
collapseNoMismatch.test <- function(seqtab, minOverlap=20, orderBy="abundance", identicalOnly=FALSE, vec=TRUE, verbose=FALSE) {
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
for(query in seqs) {
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
}
#Subset For Collapse
data.test1 <- data3[1:1000,]
dim(data3)
#Subset For Collapse
data.test1 <- data3[,1:1000]
output <- collapseNoMismatch.test(data.test1)
profvis::profvis({output <- collapseNoMismatch.test(data.test1)})
#Subset For Collapse
data.test1 <- data3[,1:10000]
profvis::profvis({output <- collapseNoMismatch.test(data.test1)})
minOverlap=20,
minOverlap=20
orderBy="abundance"
identicalOnly=FALSE
vec=TRUE
verbose=FALSE
seqtab <- data.test1
seqtab <- data3[,1:2500]
profvis::profvis({# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
for(query in seqs) {
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed})
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
lenthofseqs <-length(seqs)
for(query in seqs) {
message(paste0("Seq ",count," of ",lenthofseqs))
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
count <- count + 1
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
lenthofseqs <-length(seqs)
for(query in seqs) {
message(paste0("Seq ",count," of ",lenthofseqs))
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
count <- count + 1
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
collapseNoMismatch.test <- function(seqtab, minOverlap=20, orderBy="abundance", identicalOnly=FALSE, vec=TRUE, verbose=FALSE) {
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
lenthofseqs <-length(seqs)
for(query in seqs) {
message(paste0("Seq ",count," of ",lenthofseqs))
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
count <- count + 1
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
}
firstrun <- collapseNoMismatch.test(data3,verbose=TRUE)
system.time(firstrun <- collapseNoMismatch.test(data3,verbose=TRUE))
write.csv(firstrun,file="~/Desktop/Collapsing/SAeDNA1.1.colllpased.csv")
install.packages("dismo")
#Set some variables
minreads <- 3
items <- NULL
#Set the seed
set.seed("123456")
#Set wd and load up sediment data
setwd("~/Desktop/Analysis.SA/rawdata/")
metadat <- read.csv(file="../metadata/locations.csv")
latlongdata <- read.csv("../metadata/mapdata.csv")
View(metadat)
metadat <- read.csv(file="../metadata/locations.csv")
#Set wd and load up sediment data
setwd("~/Desktop/Analysis.SA/rawdata/")
latlongdata <- read.csv("../metadata/mapdata.csv")
#### Data Cleaning ####
files <- system2('ls',stdout=TRUE)
library("dplyr")
library("vegan")
library("reshape")
library("reshape2")
library("ggplot2")
library("stringr")
library("tidyr")
library("RColorBrewer")
library("metacoder")
library("readxl")
library("maps")
library("mapdata")
require(ggplot2)
require(ggmap)
require(mapproj)
require(rgeos)
require(maptools)
require(sp)
require(raster)
require(rgdal)
require(dismo)
library("RgoogleMaps")
library("reshape")
#Set some variables
minreads <- 3
items <- NULL
#Set the seed
set.seed("123456")
#Set wd and load up sediment data
setwd("~/Desktop/Analysis.SA/rawdata/")
metadat <- read.csv(file="../metadata/locations.csv")
latlongdata <- read.csv("../metadata/mapdata.csv")
#Set wd and load up sediment data
setwd("~/Desktop/Analysis.SA/ARCHIVE/rawdata/")
metadat <- read.csv(file="../metadata/locations.csv")
latlongdata <- read.csv("../metadata/mapdata.csv")
View(metadat)
sustr(metadat$RealID)
substr(metadat$RealID,2,5)
substr(metadat$RealID,3,5)
realID2 <- substr(metadat$RealID,3,5)
rawdat <- read.csv("../../rawdata/Prok.SAeDNA.unoise3.lulu.csv")
colnames(rawdat)
rawdat[colnames(rawdat) %in% substr(metadat$RealID[metadat$Type=="sample"],3,5)]
#Seperate controls and samples
samples <- rawdat[colnames(rawdat) %in% substr(metadat$RealID[metadat$Type=="sample"],3,5)]
View(samples)
controls <- rawdat[colnames(rawdat) %in% substr(metadat$RealID[metadat$Type=="control"],3,5)]
View(controls)
View(rawdat)
controls <- cbinc(controls,rawdat$PCR1,rawdat$PCR2)
controls <- cbind(controls,rawdat$PCR1,rawdat$PCR2)
#Filter 1 - minimum number of reads for any ID
samples[samples< minreads] <- 0
samples <- samples[rowSums(samples) > 0,]
#Filter 2 - within samples OTU must appear in more than one sample (this works becuase there are lots of reps per site and sample)
filtersam <- samples
filtersam[filtersam>0 ] <- 1
filtersam <-filtersam[rowSums(filtersam) > 1,]
samples <- samples[rownames(samples) %in% rownames(filtersam),]
#Filter 3 -Make the maximum umber of reads for each OTU in the contam the zero value in the main data
controlsCONTAM <- controls[rowSums(controls) > 0,]
for (contamOTU in 1:length(controlsCONTAM[,1])){
loopOTU <- row.names(controlsCONTAM[contamOTU,])
loopMax <- max(as.numeric(controlsCONTAM[contamOTU,]))
if (any(is.na(samples[loopOTU,]))){next}
samples[loopOTU,samples[loopOTU,]<loopMax] <- 0
print(paste("Cleaning contaminants",contamOTU))
}
test<-
samples%>%
filter(rowSums(.)>0)%>%
t(.)%>%
rrarefy(.,min(rowSums(.)))%>%
t(.)
MDSCOI <- metaMDS(t(rCOI),distance = "bray")
MDSCOI <- metaMDS(t(test),distance = "bray")
MDSCOIdat <-as.data.frame(MDSCOI$points)
plot(MDSCOIdat,type="n")
text(MDSCOIdat$MDS1,MDSCOIdat$MDS2,labels=substr(colnames(cleanedCOI),3,5))
text(MDSCOIdat$MDS1,MDSCOIdat$MDS2,labels=substr(colnames(samples)))
MDSCOI <- metaMDS(t(test),distance = "bray")
MDSCOIdat <-as.data.frame(MDSCOI$points)
plot(MDSCOIdat,type="n")
text(MDSCOIdat$MDS1,MDSCOIdat$MDS2,labels=colnames(samples))
colsums(test)
colSums(test)
test2 <- test2
test2 <- test
test2[>1]
test2[test2 > 1]
test2[test2 > 1] <- "1"
colSums(test2)
test2[test2 > 1] <- 1
colSums(test2)
test2 <- test
test2[test2 > 1] <- 1
colSums(test2)
sort(colSums(test2))
