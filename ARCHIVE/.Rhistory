dadaRs <- dada(derepRs, err=errR, multithread=TRUE)
dadaFs[[1]]
help("dada-class")
dadaFs[[2]]
dadaFs[[1]]$clustering
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
View(mergers)
mergers[1]
View(out)
seqtab <- makeSequenceTable(mergers)
View(seqtab)
table(nchar(getSequences(seqtab)))
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
system2("ls",args="-lh")
system2("usearch",)
system2("usearch",env = "PATH=PATH")
install_github("VascoElbrecht/JAMP", subdir="JAMP")
library("devtools")
install_github("VascoElbrecht/PrimerMiner", subdir="PrimerMiner")
install_github("VascoElbrecht/JAMP", subdir="JAMP")
library(JAMP)
U_truncate()
?U_truncate()
U_max_ee()
install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
?create
collapseNoMismatch <- function(seqtab, minOverlap=20, orderBy="abundance", identicalOnly=FALSE, vec=TRUE, verbose=FALSE) {
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
for(query in seqs) {
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
}
#libraries
library(dada2)
?fread
??fread
library(data.table)
rawdata <- fread("~/Desktop/finalDADA.out.csv",sep=",")
str(rawdata)
data <- as.matrix(rawdata)
datat[1,]
data[1,]
data[,1]
rownames(data)
rownames(data) <- data[,1]
rownames(data)
data2 <- data[,-1]
mode(data2)
data3 <- data2
mode(data3) <- "integer"
rowSums(data3)
rowSums(data3)
collapseNoMismatch.test <- function(seqtab, minOverlap=20, orderBy="abundance", identicalOnly=FALSE, vec=TRUE, verbose=FALSE) {
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
for(query in seqs) {
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
}
#Subset For Collapse
data.test1 <- data3[1:1000,]
dim(data3)
#Subset For Collapse
data.test1 <- data3[,1:1000]
output <- collapseNoMismatch.test(data.test1)
profvis::profvis({output <- collapseNoMismatch.test(data.test1)})
#Subset For Collapse
data.test1 <- data3[,1:10000]
profvis::profvis({output <- collapseNoMismatch.test(data.test1)})
minOverlap=20,
minOverlap=20
orderBy="abundance"
identicalOnly=FALSE
vec=TRUE
verbose=FALSE
seqtab <- data.test1
seqtab <- data3[,1:2500]
profvis::profvis({# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
for(query in seqs) {
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed})
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
lenthofseqs <-length(seqs)
for(query in seqs) {
message(paste0("Seq ",count," of ",lenthofseqs))
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
count <- count + 1
} # for(ref in seqs.out)
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
lenthofseqs <-length(seqs)
for(query in seqs) {
message(paste0("Seq ",count," of ",lenthofseqs))
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
count <- count + 1
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
collapseNoMismatch.test <- function(seqtab, minOverlap=20, orderBy="abundance", identicalOnly=FALSE, vec=TRUE, verbose=FALSE) {
# Collapse identical sequences (duplicates)
dupes <- duplicated(colnames(seqtab))
if(any(dupes)) { # Collapse duplicates first
st <- seqtab[,!dupes,drop=FALSE] # Deduplicated matrix
for(i in which(dupes)) {
sq <- colnames(seqtab)[[i]]
st[,sq] <- st[,sq] + seqtab[,i]
}
seqtab <- st # Use deduplicated sequence table going forward
}
if(identicalOnly) { return(seqtab) }
# Collapse sequences with no mismatches
unqs.srt <- sort(getUniques(seqtab), decreasing=TRUE)
seqs <- names(unqs.srt) # The input sequences in order of decreasing total abundance
seqs.out <- character(0) # The output sequences (after collapsing)
# collapsed will be the output sequence table
collapsed <- matrix(0L, nrow=nrow(seqtab), ncol=ncol(seqtab))
colnames(collapsed) <- colnames(seqtab) # Keep input ordering for output table
rownames(collapsed) <- rownames(seqtab)
count <- 1
lenthofseqs <-length(seqs)
for(query in seqs) {
message(paste0("Seq ",count," of ",lenthofseqs))
added=FALSE
prefix <- substr(query, 1, minOverlap)
for(ref in seqs.out) { # Loop over the reference sequences already added to output
prefix.ref <- substr(ref, 1, minOverlap)
# Prescreen to see if costly alignment worthwhile, this could all be moved C-side
if(grepl(prefix, ref, fixed=TRUE) || grepl(prefix.ref, query, fixed=TRUE)) {
if(nwhamming(query,ref,vec=vec,band=16) == 0) {  # band is arbitrary since need exact match
collapsed[,ref] <- collapsed[,ref] + seqtab[,query]
added=TRUE
break
}
}
} # for(ref in seqs.out)
count <- count + 1
if(!added) {
collapsed[,query] <- seqtab[,query]
seqs.out <- c(seqs.out, query)
}
} # for(query in seqs)
collapsed <- collapsed[,colnames(collapsed) %in% seqs.out,drop=FALSE]
# Order columns
if(!is.null(orderBy)) {
if(orderBy == "abundance") {
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE),drop=FALSE]
} else if(orderBy == "nsamples") {
collapsed <- collapsed[,order(colSums(collapsed>0), decreasing=TRUE),drop=FALSE]
}
}
collapsed <- collapsed[,order(colSums(collapsed), decreasing=TRUE)]
if(verbose) message("Output ", ncol(collapsed), " collapsed sequences out of ", ncol(seqtab), " input sequences.")
collapsed
}
firstrun <- collapseNoMismatch.test(data3,verbose=TRUE)
system.time(firstrun <- collapseNoMismatch.test(data3,verbose=TRUE))
write.csv(firstrun,file="~/Desktop/Collapsing/SAeDNA1.1.colllpased.csv")
getwd()
setwd("~/Desktop/Analysis.SA/ARCHIVE")
#Load in packages
library("dplyr")
library("vegan")
library("reshape")
library("reshape2")
library("ggplot2")
library("stringr")
library("tidyr")
library("RColorBrewer")
library("metacoder")
library("readxl")
library("maps")
library("mapdata")
require(ggplot2)
require(ggmap)
require(mapproj)
require(rgeos)
require(maptools)
require(sp)
require(raster)
require(rgdal)
require(dismo)
library("RgoogleMaps")
library("reshape")
#Set some variables
minreads <- 3
items <- NULL
#Set the seed
set.seed("123456")
#Set wd and load up sediment data
setwd("~/Desktop/Analysis.SA/rawdata/")
#Set wd and load up sediment data
setwd("~/Desktop/Analysis.SA/ARCHIVE")
metadat <- read.csv(file="../metadata/locations.csv")
latlongdata <- read.csv("../metadata/mapdata.csv")
#### Data Cleaning ####
files <- system2('ls',stdout=TRUE)
cleanedCOI <- read.csv("../cleaned/Cleaned.Leraylulu.unoise3.csv",row.names = 1)
cleanedCOI <- read.csv("cleaned/Cleaned.Leraylulu.unoise3.csv",row.names = 1)
rCOI<-
cleanedCOI%>%
filter(rowSums(.)>0)%>%
t(.)%>%
rrarefy(.,min(rowSums(.)))%>%
t(.)
MDSCOI <- metaMDS(t(rCOI),distance = "bray")
MDSCOIdat <-as.data.frame(MDSCOI$points)
plot(MDSCOIdat,type="n")
text(MDSCOIdat$MDS1,MDSCOIdat$MDS2,labels=substr(colnames(cleanedCOI),3,5))
cleaned18S <- read.csv("../cleaned/Cleaned.Zhanlulu.unoise3.csv",row.names = 1)
r18S<-
cleaned18S%>%
filter(rowSums(.)>0)%>%
t(.)%>%
rrarefy(.,min(rowSums(.)))%>%
t(.)
MDS18S <- metaMDS(t(r18S),distance = "bray")
MDS18Sdat <-as.data.frame(MDS18S$points)
cleanedCOI<-cbind(cleanedCOI[,1:6],cleanedCOI[,11:62])
#also get rid of all non marina sites
cleanedCOI<-cleanedCOI[,substr(colnames(cleanedCOI),3,4) %in% unique(substr(metadat$RealID[metadat$sitetype=="m"],3,4))]
#above code keeps the PE.B site in, lets get rid of it
cleanedCOI<-cleanedCOI[-grep("PE.B",colnames(cleanedCOI))]
rCOI<-
cleanedCOI%>%
filter(rowSums(.)>0)%>%
t(.)%>%
rrarefy(.,min(rowSums(.)))%>%
t(.)
View(cleanedCOI)
cleanedCOI <- read.csv("cleaned/Cleaned.Leraylulu.unoise3.csv",row.names = 1)
rCOI<-
cleanedCOI%>%
filter(rowSums(.)>0)%>%
t(.)%>%
rrarefy(.,min(rowSums(.)))%>%
t(.)
MDSCOI <- metaMDS(t(rCOI),distance = "bray")
MDSCOIdat <-as.data.frame(MDSCOI$points)
plot(MDSCOIdat,type="n")
text(MDSCOIdat$MDS1,MDSCOIdat$MDS2,labels=substr(colnames(cleanedCOI),3,5))
cleaned18S2<-cbind(cleaned18S[,1:6],cleaned18S[,11:62])
cleanedCOI2<-cbind(cleanedCOI[,1:6],cleanedCOI[,11:62])
View(cleanedCOI2)
colnames(cleanedCOI)
#required sites
sites <- c("HB","HN","SY","SN","MB","MN","KN","NK","PE","CN","RB","RN")
##COI
cleanedCOI <- read.csv("cleaned/Cleaned.Leraylulu.unoise3.csv",row.names = 1)
#required sites
sites <- c("HB","HN","SY","SN","MB","MN","KN","NK","PE","CN","RB","RN")
#new data
cleanedCOI <- cleanedCOI[grep(paste(sites,collapse="|"),names(cleanedCOI))]
#remove PE.B
cleanedCOI <- cleanedCOI[-grep("PE.B",names(cleanedCOI))]
rCOI<-
cleanedCOI%>%
filter(rowSums(.)>0)%>%
t(.)%>%
rrarefy(.,min(rowSums(.)))%>%
t(.)
MDSCOI <- metaMDS(t(rCOI),distance = "bray")
MDSCOIdat <-as.data.frame(MDSCOI$points)
palette(c("#af8dc3","#1b7837","#7fbf7b","#b35806","#2166ac","#67a9cf","#fee0b6","#762a83","#8c510a","#d8b365","#5ab4ac","#01665e"))
plot(MDSCOIdat,pch=16,cex=2, col=as.factor( substr(colnames(cleanedCOI),3,4)))
